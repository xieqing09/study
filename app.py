#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ–éŸ³å›¾ç‰‡çˆ¬è™« - Webç•Œé¢æœåŠ¡
åŸºäºFlaskçš„å¯è§†åŒ–ç•Œé¢ï¼Œæ”¯æŒç½‘å€è¾“å…¥å’Œæ–‡ä»¶ä¸Šä¼ 
"""

import asyncio
import json
import os
import threading
import time
from pathlib import Path
from queue import Queue
from typing import Dict, Any

from flask import Flask, render_template, request, jsonify, Response
from werkzeug.utils import secure_filename

# å¯¼å…¥ç°æœ‰çš„çˆ¬è™«æ¨¡å—
from douyin_image_crawler import DouyinImageCrawler
from linkrush import extract_links_from_file

app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size
app.config['UPLOAD_FOLDER'] = 'uploads'

# å…¨å±€å˜é‡
crawl_status = {
    'running': False,
    'progress': 0,
    'status': 'å‡†å¤‡å¼€å§‹...',
    'results': None,
    'error': None
}

# æ¶ˆæ¯é˜Ÿåˆ—ç”¨äºå®æ—¶é€šä¿¡
message_queue = Queue()
crawl_thread = None

class CrawlProgressHandler:
    """çˆ¬è™«è¿›åº¦å¤„ç†å™¨"""
    
    def __init__(self):
        self.total_images = 0
        self.processed_images = 0
        self.downloaded_images = 0
        self.failed_images = 0
        
    def update_total(self, total: int):
        """æ›´æ–°æ€»å›¾ç‰‡æ•°"""
        self.total_images = total
        self._send_progress()
        
    def update_processed(self, processed: int, downloaded: int, failed: int):
        """æ›´æ–°å¤„ç†è¿›åº¦"""
        self.processed_images = processed
        self.downloaded_images = downloaded
        self.failed_images = failed
        self._send_progress()
        
    def send_log(self, message: str):
        """å‘é€æ—¥å¿—æ¶ˆæ¯"""
        message_queue.put({
            'type': 'log',
            'message': message
        })
        
    def _send_progress(self):
        """å‘é€è¿›åº¦æ›´æ–°"""
        if self.total_images > 0:
            progress = int((self.processed_images / self.total_images) * 100)
        else:
            progress = 0
            
        status = f"å·²å¤„ç† {self.processed_images}/{self.total_images} å¼ å›¾ç‰‡ (æˆåŠŸ: {self.downloaded_images}, å¤±è´¥: {self.failed_images})"
        
        message_queue.put({
            'type': 'progress',
            'progress': progress,
            'status': status
        })

# åˆ›å»ºä¸Šä¼ ç›®å½•
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')

@app.route('/start_crawl', methods=['POST'])
def start_crawl():
    """å¼€å§‹çˆ¬å–"""
    global crawl_thread, crawl_status
    
    if crawl_status['running']:
        return jsonify({'success': False, 'error': 'çˆ¬å–æ­£åœ¨è¿›è¡Œä¸­'})
    
    try:
        # è·å–å‚æ•°
        crawl_type = request.form.get('crawl_type')
        save_dir = request.form.get('save_dir', 'douyin_images')
        max_images = int(request.form.get('max_images', 50))
        use_selenium = request.form.get('use_selenium') == 'true'
        save_metadata = request.form.get('save_metadata') == 'true'
        
        # å¤„ç†ä¿å­˜è·¯å¾„ - æ”¯æŒç»å¯¹è·¯å¾„å’Œç›¸å¯¹è·¯å¾„
        save_dir = save_dir.strip()
        if not save_dir:
            save_dir = 'douyin_images'
        
        # åŸºæœ¬è·¯å¾„å®‰å…¨æ£€æŸ¥
        if '..' in save_dir or save_dir.startswith('/') and os.name == 'nt':
            return jsonify({'success': False, 'error': 'è·¯å¾„åŒ…å«ä¸å®‰å…¨å­—ç¬¦'})
        
        # è½¬æ¢ä¸ºPathå¯¹è±¡ä»¥ä¾¿å¤„ç†
        try:
            save_path = Path(save_dir)
        except Exception as e:
            return jsonify({'success': False, 'error': f'è·¯å¾„æ ¼å¼æ— æ•ˆ: {str(e)}'})
        
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œåˆ™ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•
        if not save_path.is_absolute():
            save_path = Path.cwd() / save_path
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        try:
            save_path.mkdir(parents=True, exist_ok=True)
            save_dir = str(save_path.resolve())  # è·å–ç»å¯¹è·¯å¾„
        except PermissionError:
            return jsonify({'success': False, 'error': 'æ²¡æœ‰æƒé™åˆ›å»ºè¯¥ç›®å½•ï¼Œè¯·æ£€æŸ¥è·¯å¾„æƒé™'})
        except Exception as e:
            return jsonify({'success': False, 'error': f'æ— æ³•åˆ›å»ºä¿å­˜ç›®å½•: {str(e)}'})
        
        print(f"ä¿å­˜è·¯å¾„è®¾ç½®ä¸º: {save_dir}")
        
        # æ ¹æ®çˆ¬å–ç±»å‹è·å–URLåˆ—è¡¨
        urls = []
        
        if crawl_type == 'url':
            url = request.form.get('url')
            if not url:
                return jsonify({'success': False, 'error': 'è¯·æä¾›æœ‰æ•ˆçš„URL'})
            
            # æ¸…ç†URLè¾“å…¥ï¼Œå»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦å’Œå¼•å·
            original_url = url
            url = url.strip().strip('\'"`')
            
            # å¦‚æœURLåŒ…å«å¤šè¡Œæˆ–å¤šä¸ªURLï¼Œåªå–ç¬¬ä¸€ä¸ª
            if '\n' in url:
                url = url.split('\n')[0].strip()
            
            print(f"ç½‘å€çˆ¬å– - åŸå§‹URL: {repr(original_url)}")
            print(f"ç½‘å€çˆ¬å– - æ¸…ç†åURL: {repr(url)}")
            
            urls = [url]
            
        elif crawl_type == 'file':
            file = request.files.get('file')
            if not file or file.filename == '':
                return jsonify({'success': False, 'error': 'è¯·é€‰æ‹©æ–‡ä»¶'})
            
            # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
            filename = secure_filename(file.filename)
            file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(file_path)
            
            # ä»æ–‡ä»¶ä¸­æå–é“¾æ¥
            try:
                urls = extract_links_from_file(file_path)
                print(f"æ–‡æ¡£çˆ¬å– - ä»æ–‡ä»¶æå–çš„URLs: {urls}")
                if not urls:
                    return jsonify({'success': False, 'error': 'æ–‡ä»¶ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„é“¾æ¥'})
            except Exception as e:
                return jsonify({'success': False, 'error': f'è§£ææ–‡ä»¶å¤±è´¥: {str(e)}'})
        else:
            return jsonify({'success': False, 'error': 'æ— æ•ˆçš„çˆ¬å–ç±»å‹'})
        
        # é‡ç½®çŠ¶æ€
        crawl_status.update({
            'running': True,
            'progress': 0,
            'status': 'å‡†å¤‡å¼€å§‹...',
            'results': None,
            'error': None
        })
        
        # æ¸…ç©ºæ¶ˆæ¯é˜Ÿåˆ—
        while not message_queue.empty():
            message_queue.get()
        
        # å¯åŠ¨çˆ¬å–çº¿ç¨‹
        crawl_thread = threading.Thread(
            target=run_crawl_task,
            args=(urls, save_dir, max_images, use_selenium, save_metadata)
        )
        crawl_thread.daemon = True
        crawl_thread.start()
        
        return jsonify({'success': True, 'message': 'çˆ¬å–ä»»åŠ¡å·²å¯åŠ¨'})
        
    except Exception as e:
        crawl_status['running'] = False
        return jsonify({'success': False, 'error': f'å¯åŠ¨å¤±è´¥: {str(e)}'})

@app.route('/stop_crawl', methods=['POST'])
def stop_crawl():
    """åœæ­¢çˆ¬å–"""
    global crawl_status
    
    crawl_status['running'] = False
    message_queue.put({
        'type': 'log',
        'message': 'æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢çˆ¬å–...'
    })
    
    return jsonify({'success': True, 'message': 'åœæ­¢ä¿¡å·å·²å‘é€'})

@app.route('/progress')
def progress():
    """SSEè¿›åº¦æ¨é€"""
    def generate():
        while True:
            try:
                # è·å–æ¶ˆæ¯
                if not message_queue.empty():
                    message = message_queue.get_nowait()
                    yield f"data: {json.dumps(message, ensure_ascii=False)}\n\n"
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if not crawl_status['running'] and crawl_status.get('results'):
                    yield f"data: {json.dumps({'type': 'complete', 'results': crawl_status['results']}, ensure_ascii=False)}\n\n"
                    break
                elif not crawl_status['running'] and crawl_status.get('error'):
                    yield f"data: {json.dumps({'type': 'error', 'message': crawl_status['error']}, ensure_ascii=False)}\n\n"
                    break
                
                time.sleep(0.5)  # é¿å…è¿‡äºé¢‘ç¹çš„æ£€æŸ¥
                
            except Exception as e:
                yield f"data: {json.dumps({'type': 'error', 'message': str(e)}, ensure_ascii=False)}\n\n"
                break
    
    return Response(generate(), mimetype='text/event-stream')

def run_crawl_task(urls, save_dir, max_images, use_selenium, save_metadata):
    """è¿è¡Œçˆ¬å–ä»»åŠ¡"""
    global crawl_status
    
    progress_handler = CrawlProgressHandler()
    
    try:
        progress_handler.send_log(f"å¼€å§‹çˆ¬å–ä»»åŠ¡ï¼Œå…± {len(urls)} ä¸ªURL")
        progress_handler.send_log(f"ä¿å­˜ç›®å½•: {save_dir}")
        progress_handler.send_log(f"æœ€å¤§å›¾ç‰‡æ•°: {max_images}")
        progress_handler.send_log(f"ä½¿ç”¨Selenium: {use_selenium}")
        
        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        crawler = DouyinImageCrawler(download_dir=save_dir)
        
        total_results = {
            'total_images': 0,
            'downloaded_images': 0,
            'failed_downloads': 0,
            'processed_urls': 0,
            'method_used': 'selenium' if use_selenium else 'crawl4ai',
            'save_path': str(Path(save_dir).absolute()),
            'url_results': []
        }
        
        # å¤„ç†æ¯ä¸ªURL
        for i, url in enumerate(urls):
            if not crawl_status['running']:
                progress_handler.send_log("çˆ¬å–å·²è¢«ç”¨æˆ·åœæ­¢")
                break
                
            progress_handler.send_log(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1}/{len(urls)} ä¸ªURL: {url}")
            
            try:
                # è¿è¡Œå¼‚æ­¥çˆ¬å–
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                result = loop.run_until_complete(
                    crawler.crawl_douyin_user_images(
                        user_url=url,
                        max_images=max_images,
                        save_metadata=save_metadata,
                        use_selenium=use_selenium
                    )
                )
                
                loop.close()
                
                # æ›´æ–°æ€»ç»“æœ
                total_results['total_images'] += result.get('total_images', 0)
                total_results['downloaded_images'] += result.get('downloaded_images', 0)
                total_results['failed_downloads'] += result.get('failed_downloads', 0)
                total_results['processed_urls'] += 1
                total_results['url_results'].append({
                    'url': url,
                    'result': result
                })
                
                progress_handler.send_log(
                    f"URL {i+1} å®Œæˆ: ä¸‹è½½ {result.get('downloaded_images', 0)} å¼ å›¾ç‰‡"
                )
                
                # æ›´æ–°è¿›åº¦
                progress_handler.update_processed(
                    i + 1,
                    total_results['downloaded_images'],
                    total_results['failed_downloads']
                )
                
            except Exception as e:
                error_msg = f"å¤„ç†URL {url} æ—¶å‡ºé”™: {str(e)}"
                progress_handler.send_log(error_msg)
                total_results['url_results'].append({
                    'url': url,
                    'error': str(e)
                })
        
        # å®Œæˆ
        crawl_status['results'] = total_results
        crawl_status['running'] = False
        
        progress_handler.send_log("çˆ¬å–ä»»åŠ¡å®Œæˆï¼")
        progress_handler.send_log(f"æ€»è®¡ä¸‹è½½ {total_results['downloaded_images']} å¼ å›¾ç‰‡")
        
    except Exception as e:
        error_msg = f"çˆ¬å–ä»»åŠ¡å¤±è´¥: {str(e)}"
        progress_handler.send_log(error_msg)
        crawl_status['error'] = error_msg
        crawl_status['running'] = False

@app.route('/status')
def get_status():
    """è·å–å½“å‰çŠ¶æ€"""
    return jsonify(crawl_status)

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ‰ æŠ–éŸ³å›¾ç‰‡çˆ¬è™« - Webç•Œé¢æœåŠ¡")
    print("=" * 60)
    print("ğŸ“± è®¿é—®åœ°å€: http://localhost:5000")
    print("ğŸ”§ åŠŸèƒ½ç‰¹æ€§:")
    print("   â€¢ æ”¯æŒå•ä¸ªURLçˆ¬å–")
    print("   â€¢ æ”¯æŒæ‰¹é‡æ–‡ä»¶çˆ¬å–")
    print("   â€¢ å®æ—¶è¿›åº¦æ˜¾ç¤º")
    print("   â€¢ Seleniumæ¨¡å¼æ”¯æŒ")
    print("   â€¢ è‡ªå®šä¹‰ä¿å­˜ç›®å½•")
    print("=" * 60)
    print("âš ï¸  æ³¨æ„äº‹é¡¹:")
    print("   â€¢ è¯·éµå®ˆæŠ–éŸ³å¹³å°ä½¿ç”¨æ¡æ¬¾")
    print("   â€¢ å»ºè®®é€‚åº¦ä½¿ç”¨ï¼Œé¿å…é¢‘ç¹è¯·æ±‚")
    print("   â€¢ ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š")
    print("=" * 60)
    
    app.run(debug=True, host='0.0.0.0', port=5000, threaded=True)